{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\synthesis-project-II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pol.AEpproach.src.modelPCA import Autoencoder\n",
    "import torch\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "from Paula.GCN import GCNModel\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(166, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 86),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(86, 48),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(48, 86),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(86, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 166),\n",
    "            nn.LeakyReLU() \n",
    "        )\n",
    "    \n",
    "    def forward(self, in_features):\n",
    "        encoded_features = self.encoder(in_features)\n",
    "        out = self.decoder(encoded_features)\n",
    "        return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats, allow_zero_in_degree=True)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#load datasets\n",
    "df_classes = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_classes.csv\")\n",
    "df_edges = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_edgelist.csv\")\n",
    "df_features = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_features.csv\", header=None)\n",
    "\n",
    "df_classes = df_classes[df_classes['class'] != \"unknown\"]\n",
    "# Change column names --> Column 1 is txId, Column 2 is timestep and the rest are unknown features\n",
    "df_features.columns = ['txId', 'timestep'] + ['f' + str(i) for i in range(165)]\n",
    "\n",
    "# Remove all edges that do not appear in classesDF\n",
    "df_features = df_features[df_features['txId'].isin(df_classes['txId'])]\n",
    "\n",
    "df_edges = df_edges[df_edges['txId1'].isin(df_classes['txId']) & df_edges['txId2'].isin(df_classes['txId'])]\n",
    "\n",
    "# Identifica los nodos en df_classes y df_features\n",
    "nodos_classes = set(df_classes['txId'])\n",
    "nodos_features = set(df_features['txId'])\n",
    "\n",
    "# Encuentra la intersección de nodos entre clases y características\n",
    "nodos_comunes = nodos_classes.intersection(nodos_features)\n",
    "\n",
    "# Filtrar df_edges para asegurar que ambos nodos de cada arista estén en nodos_comunes\n",
    "df_edges = df_edges[df_edges['txId1'].isin(nodos_comunes) & df_edges['txId2'].isin(nodos_comunes)]\n",
    "\n",
    "# Filtrar df_features y df_classes para incluir solo los nodos comunes\n",
    "df_features = df_features[df_features['txId'].isin(nodos_comunes)]\n",
    "df_classes = df_classes[df_classes['txId'].isin(nodos_comunes)]\n",
    "\n",
    "# Asegurarte de que df_edges solo contiene nodos presentes en los otros DataFrames\n",
    "assert all(df_edges['txId1'].isin(df_features['txId']))\n",
    "assert all(df_edges['txId2'].isin(df_features['txId']))\n",
    "\n",
    "# Verificar que df_features y df_classes contienen los mismos nodos\n",
    "assert set(df_features['txId']) == set(df_classes['txId'])\n",
    "\n",
    "#We assign 0 to ilicit transacions and 1 to licit ones\n",
    "df_classes['class'] = df_classes['class'].replace({'1': 0, '2': 1})\n",
    "\n",
    "unique_nodes_classes = df_classes['txId'].nunique()\n",
    "\n",
    "unique_nodes_edges = pd.concat([df_edges['txId1'], df_edges['txId2']]).nunique()\n",
    "\n",
    "unique_nodes_features = df_features['txId'].nunique()\n",
    "\n",
    "#reindexar los nodos para que empicen desde 0\n",
    "node_mapping = {old_id: new_id for new_id, old_id in enumerate(df_features['txId'].unique())}\n",
    "\n",
    "# Aplicar este mapeo a df_edges para actualizar los identificadores de nodos a la nueva secuencia\n",
    "df_edges['txId1'] = df_edges['txId1'].map(node_mapping)\n",
    "df_edges['txId2'] = df_edges['txId2'].map(node_mapping)\n",
    "\n",
    "# Ahora, cuando crees el grafo y asignes características y etiquetas, el tamaño debería coincidir\n",
    "g = dgl.graph((df_edges['txId1'].values, df_edges['txId2'].values))\n",
    "g.ndata['feat'] = torch.tensor(df_features.iloc[:, 2:].values, dtype=torch.float32)  # Asumiendo que las dos primeras columnas no son características\n",
    "g.ndata['label'] = torch.tensor(df_classes['class'].astype(int).values, dtype=torch.long)  # Asegurándonos de que las clases están en formato numérico\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargar todos los modelos\n",
    "\n",
    "#autoencoder\n",
    "model_AE = Autoencoder()\n",
    "model_AE.load_state_dict(torch.load(r'C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\synthesis-project-II\\Pol\\AEpproach\\models\\Autoencoder_secondRUN.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "#random forest\n",
    "randomforest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#contrastive\n",
    "#contrastive = \n",
    "\n",
    "#GCN\n",
    "\n",
    "GCN = GCNModel(g.ndata['feat'].shape[1], 16, 2) \n",
    "GCN.load_state_dict(torch.load(r'C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\synthesis-project-II\\Paula\\best_model_GCN.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
